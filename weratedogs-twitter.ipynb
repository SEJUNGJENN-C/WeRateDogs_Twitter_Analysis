{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\nimport requests\nimport time\nimport json\n!pip install tweepy\nimport tweepy\n!pip install wptools\nimport wptools\nfrom PIL import Image\nfrom io import BytesIO","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-15T11:04:52.790371Z","iopub.execute_input":"2022-10-15T11:04:52.790814Z","iopub.status.idle":"2022-10-15T11:05:14.609134Z","shell.execute_reply.started":"2022-10-15T11:04:52.790702Z","shell.execute_reply":"2022-10-15T11:05:14.608081Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tweepy in /opt/conda/lib/python3.7/site-packages (4.10.1)\nRequirement already satisfied: requests<3,>=2.27.0 in /opt/conda/lib/python3.7/site-packages (from tweepy) (2.28.1)\nRequirement already satisfied: requests-oauthlib<2,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from tweepy) (1.3.1)\nRequirement already satisfied: oauthlib<4,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from tweepy) (3.2.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.27.0->tweepy) (2022.6.15.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.27.0->tweepy) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.27.0->tweepy) (1.26.12)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.27.0->tweepy) (2.1.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: wptools in /opt/conda/lib/python3.7/site-packages (0.4.17)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from wptools) (2022.6.15.2)\nRequirement already satisfied: pycurl in /opt/conda/lib/python3.7/site-packages (from wptools) (7.45.1)\nRequirement already satisfied: html2text in /opt/conda/lib/python3.7/site-packages (from wptools) (2020.1.16)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.7/site-packages (from wptools) (4.9.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"1. Directly download weratedogs twitter archive .csv file","metadata":{}},{"cell_type":"code","source":"tweets = pd.read_csv(\"../input/weratedogs-twitter-archive-enhanced/twitter-archive-enhanced.csv\")\ntweets.head(1)","metadata":{"execution":{"iopub.status.busy":"2022-10-15T11:05:23.587989Z","iopub.execute_input":"2022-10-15T11:05:23.588711Z","iopub.status.idle":"2022-10-15T11:05:23.648754Z","shell.execute_reply.started":"2022-10-15T11:05:23.588654Z","shell.execute_reply":"2022-10-15T11:05:23.647577Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"             tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n0  892420643555336193                    NaN                  NaN   \n\n                   timestamp  \\\n0  2017-08-01 16:23:56 +0000   \n\n                                              source  \\\n0  <a href=\"http://twitter.com/download/iphone\" r...   \n\n                                                text  retweeted_status_id  \\\n0  This is Phineas. He's a mystical boy. Only eve...                  NaN   \n\n   retweeted_status_user_id retweeted_status_timestamp  \\\n0                       NaN                        NaN   \n\n                                       expanded_urls  rating_numerator  \\\n0  https://twitter.com/dog_rates/status/892420643...                13   \n\n   rating_denominator     name doggo floofer pupper puppo  \n0                  10  Phineas  None    None   None  None  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>in_reply_to_status_id</th>\n      <th>in_reply_to_user_id</th>\n      <th>timestamp</th>\n      <th>source</th>\n      <th>text</th>\n      <th>retweeted_status_id</th>\n      <th>retweeted_status_user_id</th>\n      <th>retweeted_status_timestamp</th>\n      <th>expanded_urls</th>\n      <th>rating_numerator</th>\n      <th>rating_denominator</th>\n      <th>name</th>\n      <th>doggo</th>\n      <th>floofer</th>\n      <th>pupper</th>\n      <th>puppo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892420643555336193</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2017-08-01 16:23:56 +0000</td>\n      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n      <td>This is Phineas. He's a mystical boy. Only eve...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>https://twitter.com/dog_rates/status/892420643...</td>\n      <td>13</td>\n      <td>10</td>\n      <td>Phineas</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"2. Download the tweet image prediction .tsv file using url","metadata":{}},{"cell_type":"code","source":"folder = 'tweet_tsv'\nurl = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n\nif not os.path.exists(folder):\n    os.makedirs(folder)\n    \nr = requests.get(url)\nwith open(os.path.join(folder, url.split(\"/\")[-1]), mode='wb') as file:\n    response = file.write(r.content)","metadata":{"execution":{"iopub.status.busy":"2022-10-15T11:05:26.076876Z","iopub.execute_input":"2022-10-15T11:05:26.077810Z","iopub.status.idle":"2022-10-15T11:05:26.881950Z","shell.execute_reply.started":"2022-10-15T11:05:26.077741Z","shell.execute_reply":"2022-10-15T11:05:26.880842Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"image = pd.read_csv('./tweet_tsv/image-predictions.tsv', sep='\\t')\nimage.head(1)","metadata":{"execution":{"iopub.status.busy":"2022-10-15T11:05:26.884102Z","iopub.execute_input":"2022-10-15T11:05:26.884547Z","iopub.status.idle":"2022-10-15T11:05:26.912558Z","shell.execute_reply.started":"2022-10-15T11:05:26.884506Z","shell.execute_reply":"2022-10-15T11:05:26.911472Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"             tweet_id                                          jpg_url  \\\n0  666020888022790149  https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg   \n\n   img_num                      p1   p1_conf  p1_dog      p2   p2_conf  \\\n0        1  Welsh_springer_spaniel  0.465074    True  collie  0.156665   \n\n   p2_dog                 p3   p3_conf  p3_dog  \n0    True  Shetland_sheepdog  0.061428    True  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>jpg_url</th>\n      <th>img_num</th>\n      <th>p1</th>\n      <th>p1_conf</th>\n      <th>p1_dog</th>\n      <th>p2</th>\n      <th>p2_conf</th>\n      <th>p2_dog</th>\n      <th>p3</th>\n      <th>p3_conf</th>\n      <th>p3_dog</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>666020888022790149</td>\n      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\n      <td>1</td>\n      <td>Welsh_springer_spaniel</td>\n      <td>0.465074</td>\n      <td>True</td>\n      <td>collie</td>\n      <td>0.156665</td>\n      <td>True</td>\n      <td>Shetland_sheepdog</td>\n      <td>0.061428</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"3. Use tweepy library to query additional data via the Twitter API\n(tweet_json.txt):\n    * Tweepy (twitter api) allows us to mine the data of any twitter user. Using .get_status of the API class in tweepy module fetch a status(tweet)","metadata":{}},{"cell_type":"code","source":"consumer_key = 'mP9YUkyksJ3gGBcmLWWNjG1HK'\nconsumer_secret = 'O9joKKsymUtGXMg0rsUsr4uKm3J44y5nfadefJHm3sDWBget0b'\naccess_token = '1577688773621694465-rWwJYImL2LRjB37xJAHr51cxSECQ9G'\naccess_token_secret = '9Zvzb6dNMmAe8wTI9Ppzcsv7z63aRX5MgspDP9hHJOS0M' \n\nauth = tweepy.OAuthHandler(consumer_key, consumer_secret)\nauth.set_access_token(access_token, access_token_secret)\n# add `wait_on_rate_limit` parameter to automatically wait for rate limits to replenish\napi = tweepy.API(auth, parser=tweepy.parsers.JSONParser(), wait_on_rate_limit=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\n\n# Save all JSON data of each tweet and save the queries into a 'tweet_json.txt' file \n# so that you only need to run the following long queries once.\nwith open ('tweet_json.txt', 'w') as file:\n    for tweet_id in tweets['tweet_id']:\n        try:\n            # Get status/tweet for each tweet_id\n            tweet = api.get_status(tweet_id, tweet_mode='extended')\n            # Convert into .json string using .dumps() function \n            # Also, add '\\n' as each tweet's JSON data to be written to its own line\n            file.write(json.dumps(tweet) + \"\\n\") \n        except Exception as e:\n            # if error occurs, print tweet_id and error message\n            print(\"No tweet found for {} with error message: {}\".format(str(tweet_id), str(e)))\n            \nend_time = time.time()\nprint(\"The process finished in {} seconds\".format(end_time - start_time))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read JSON line by line and create a python dictionary\ninfo = []\n\nwith open('tweet_json.txt', 'r') as json_file:\n    for line in json_file:\n        # Parse JSON encoded/formatted string line by line\n        json_data = json.loads(line)\n        # Create a dictionary\n        info.append({'tweet_id': json_data['id'], #call the value by stating 'key'\n                    'favorites': json_data['favorite_count'],\n                     'retweets': json_data['retweet_count'],\n                     'timestamp': json_data['created_at']\n                    })\n\n# Create a dataframe\nadditional = pd.DataFrame(info, columns=['tweet_id', 'favorites', 'retweets', 'timestamp'])\n\n# Optional: Save the dataframe to .csv and add the data into this notebook.\n# Doing so, you don't have to use twitter api everytime you reboot this notebook, which takes a significant amount of time. .\n# additional.to_csv('additional.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"additional = pd.read_csv(\"./additional.csv\")\nadditional.head(1)","metadata":{"execution":{"iopub.status.busy":"2022-10-15T11:05:31.568809Z","iopub.execute_input":"2022-10-15T11:05:31.569754Z","iopub.status.idle":"2022-10-15T11:05:31.585853Z","shell.execute_reply.started":"2022-10-15T11:05:31.569710Z","shell.execute_reply":"2022-10-15T11:05:31.584547Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"             tweet_id  favorites  retweets                       timestamp\n0  892420643555336193      33594      6950  Tue Aug 01 16:23:56 +0000 2017","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>favorites</th>\n      <th>retweets</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892420643555336193</td>\n      <td>33594</td>\n      <td>6950</td>\n      <td>Tue Aug 01 16:23:56 +0000 2017</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Quality issues\n##### tweets\n1. Drop retweets rows (for all tables)\n2. More rows than image (indicating there are tweets without pictures)\n3. Other forms of Nan values(e.g. \"None\") ë¯¸\n\n##### image_predict\n1. Inconsistencies in upper/lowercase in `p1`, `p2`, `p3` \n2. Inconsistencies in upper/lowercase in dog breed predictions\n3. Inconsistencies in the length of decimal numbers: `p1_conf`, `p2_conf`, `p3_conf`\n\n##### additional\n1. drop retweet rows\n2. `rating_denominator` should be 10","metadata":{}},{"cell_type":"markdown","source":"### Tidiness issues \n##### tweets table\n1. Unnecessary columns that could be joined into one `stage` column with possible values of doggo, floofer, pupper, or puppo\n2. Unnecessary columns with too many null values: `in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_id`,`retweeted_status_user_id`,`retweeted_status_timestamp`.\n3. Wrong datatypes `tweet_id`, `timestamp`  \n\n##### image table\n1. A column needed for actual dog breed, not falsely predicted object \n2. Wrong datatype `tweet_id`\n\n##### additional table\n1. Wrong data types of `tweet_id`, `timestamp` columns. Ignore `timestamp` for now as we will drop the column later.\n2. Duplicate `timestamp` information in both df1 and df2 datasets","metadata":{"execution":{"iopub.status.busy":"2022-10-15T09:38:46.529185Z","iopub.execute_input":"2022-10-15T09:38:46.530471Z","iopub.status.idle":"2022-10-15T09:38:46.538638Z","shell.execute_reply.started":"2022-10-15T09:38:46.530425Z","shell.execute_reply":"2022-10-15T09:38:46.537313Z"}}},{"cell_type":"code","source":"# Before any cleaning, make a copy of original datasets.\ntweets_clean = tweets.copy()\nimage_clean = image.copy()\nadd_clean = additional.copy()","metadata":{"execution":{"iopub.status.busy":"2022-10-15T11:06:12.622093Z","iopub.execute_input":"2022-10-15T11:06:12.622545Z","iopub.status.idle":"2022-10-15T11:06:12.628982Z","shell.execute_reply.started":"2022-10-15T11:06:12.622505Z","shell.execute_reply":"2022-10-15T11:06:12.628130Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"##### Clean 1 (all tables)\nDefine: \n- Drop retweet cases from all tables as this project will only analyse original ratings that have image (no retweets)\n\nCode 1: merge tables","metadata":{"execution":{"iopub.status.busy":"2022-10-14T16:26:38.651787Z","iopub.execute_input":"2022-10-14T16:26:38.652174Z","iopub.status.idle":"2022-10-14T16:26:38.658308Z","shell.execute_reply.started":"2022-10-14T16:26:38.652144Z","shell.execute_reply":"2022-10-14T16:26:38.657221Z"}}},{"cell_type":"code","source":"# Merge `text` column to image and additional table on='tweet_id'.\n# To do so, first, create a separate table with identifier column `tweet_id` and `text`.\ntexts = tweets_clean[['tweet_id', 'text']]\n\n# Merge\nimage_clean = pd.merge(image_clean, texts, on='tweet_id')\nadd_clean = pd.merge(add_clean, texts, on='tweet_id')\n\n# Confirm\nimage_clean.columns, add_clean.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Code 2: remove retweets","metadata":{}},{"cell_type":"code","source":"# First, define a function that returns a mask of retweet entries.\ndef rt_mask(table):\n    mask = table.text.str.contains(\"RT\")\n    return mask\n\n# Drop retweet rows using the function.\ntweets_clean = tweets_clean[~rt_mask(tweets_clean)]\nimage_clean = image_clean[~rt_mask(image_clean)]\nadd_clean = add_clean[~rt_mask(add_clean)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confirm if there is any RT left in tables. You should get False's.\nprint(tweets_clean[tweets_clean['text'].str.contains('RT')].sum().any()),\nprint(image_clean[image_clean['text'].str.contains('RT')].sum().any()),\nprint(add_clean[add_clean['text'].str.contains('RT')].sum().any())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Once it is confirmed, drop the redudant `text` columns from previously merged tables.\nimage_clean.drop('text', axis=1, inplace=True)\nadd_clean.drop('text', axis=1, inplace=True)\n\n# Confirm. Column `text` should not be included in a duplicated series.\nall_col = pd.Series(list(tweets_clean) + list(image_clean) + list(add_clean))\nall_col[all_col.duplicated()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Clean 2 (all tables) \nDefine: \n- More rows than image (indicating there are tweets without pictures) \n\nCode 1:","metadata":{}},{"cell_type":"code","source":"# Extract `tweet_id` from image_clean and make it into a list\nid_list = list(image_clean.tweet_id)\n\n# Then, query only the rows with `tweet_id` in image_clean table.\ntweets_clean = tweets_clean[tweets_clean['tweet_id'].isin(id_list)]\nadd_clean = add_clean[add_clean['tweet_id'].isin(id_list)]\n\n# If you want to replace the two above lines with a defined function, use below code.\n# def id_select(table, varName='tweet_id'): # arguments with '=' are set as a default\n    # table = table[table[varName]].isin(id_list)\n    # return table","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confirm with boolean statement. You should get two True's\nprint(tweets_clean.tweet_id.isin(image_clean.tweet_id).sum().any(),\nadd_clean.tweet_id.isin(image_clean.tweet_id).sum().any())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> self-study note: <br>\n\nwhen creating a function,\n1. Avoid using actual dataframe names in your function - the placeholder can be replaced with an actual dataframe name later (and python can actually use global variables inside functions, so it is error prone)\n2. Including optional arguments, like varName, allows you to use the function for different columns while, at the same time, using the default when you call the function.\n3. Using a return statement allows you to use a different dataframe name for the result. This avoids over-writing already existing dataframes.","metadata":{}},{"cell_type":"markdown","source":"##### Clean 2 (tweets_clean)\nDefine:\nDrop unnecessary columns with too many null values\n\nCode:","metadata":{}},{"cell_type":"code","source":"# Make a list of columns to drop\ndrop_cols = ['in_reply_to_status_id', 'in_reply_to_user_id', 'retweeted_status_id','retweeted_status_user_id','retweeted_status_timestamp']\n\n# Drop\ntweets_clean.drop(columns = drop_cols, inplace=True)\n\n# Confirm\ntweets_clean.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Clean 3 (tweets_clean)\nDefine: \nJoin redundant columns into `stage` column with possible values of doggo, floofer, pupper, or puppo\n\nCode:","metadata":{}},{"cell_type":"code","source":"# By running the code below, you can see that other than empty space or actual stage, \"None\" string value is included in the column value.\nprint(\"doggo: {}, floofer: {}, puppo: {}, pupper:{}\"\n     .format(tweets_clean.doggo.unique(), \n            tweets_clean.floofer.unique(),\n            tweets_clean.puppo.unique(),\n            tweets_clean.pupper.unique()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# So before joining the four columns, first replace \"None\" to empty-space \"\".\n# Then join the columns.\n# Some columns for example will be \"   floofer \", reflecting empty spaces created by joining the columns. So strip those empty spaces.\ntweets_clean['stage'] = (tweets_clean[['doggo', 'floofer', 'puppo', 'pupper']]\n                         .replace(\"None\",\"\").apply(lambda x: \" \".join(x), axis=1).str.strip())\n\n# Confirm if merge successful.\ntweets_clean.query(\"stage != ''\").head(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop the redundant columns\ntweets_clean.drop(columns = ['doggo', 'floofer', 'pupper', 'puppo'], inplace=True)\n\n# Confirm\ntweets_clean.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Clean 3 (all tables)\nDefine: \n- Convert wrong datatypes\n\nCode:","metadata":{}},{"cell_type":"code","source":"# Create a function that converts wrong datatypes with input arguments (table)\ndef change_dtypes(table):\n    for col in table.columns:\n        if col[-3:] == \"_id\":\n            table[col] = table[col].astype(str)\n        elif col[-5:] == \"stamp\":\n            table[col] = pd.to_datetime(table[col])\n        else:\n            table[col] = table[col]\n            \n# Call the function\nchange_dtypes(tweets_clean)\nchange_dtypes(image_clean)\nchange_dtypes(add_clean)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confirm\ntweets_clean.dtypes, image_clean.dtypes, add_clean.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Clean 4 (image_clean)\nDefine: \n- Create an new column for actual breed of a dog, not falsely predicted breed.\n\nCode:\n- np.where(condition, value if condition True, value if condition False)\n- Since the prediction p1, p2, p3 is hierarchical, if the first prediction is True (i.e. is a dog), that is the prediction you want. If False (i.e. not a dog), move onto the second prediction\n- `px_dog` is vectorised, so you can just use the column itself as a condition in np.where() ","metadata":{}},{"cell_type":"code","source":"image_clean['dog_breed'] = np.where(image_clean['p1_dog'], image_clean['p1'],\n                                   np.where(image_clean['p2_dog'], image_clean['p2'],\n                                           np.where(image_clean['p3_dog'], image_clean['p3'],\n                                           np.nan)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confirm\nimage_clean.sample(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Clean 5 (all tables)\nDefine: \n- Drop any duplicate columns amongst tables\n\nCode:","metadata":{"execution":{"iopub.status.busy":"2022-10-14T17:26:52.263302Z","iopub.execute_input":"2022-10-14T17:26:52.263741Z","iopub.status.idle":"2022-10-14T17:26:52.270625Z","shell.execute_reply.started":"2022-10-14T17:26:52.263703Z","shell.execute_reply":"2022-10-14T17:26:52.269049Z"}}},{"cell_type":"code","source":"# Look for duplicated columns\nall_cols = pd.Series(list(tweets_clean) + list(image_clean) + list(add_clean))\nall_cols[all_cols.duplicated()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop `timestamp` column from `add_clean` table as it is irrelevant to table's observational unit\nadd_clean.drop('timestamp', axis=1, inplace=True)\n\n# Confirm\nadd_clean.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Clean 6 (image_clean)\nDefine: \n- Lowercase all breed values in `p1`, `p2`, `p3`, `dog_breed` columns\n- Lowercase `dog_breed` column \n- Standardise the length of decimal numbers in `p1_conf`, `p2_conf`, `p3_conf`: .round()\n\nCode 1:","metadata":{}},{"cell_type":"code","source":"# Lowercase\ndef lowercase(table):\n    breed_cols = ['p1', 'p2', 'p3', 'dog_breed']\n    for c in table.columns:\n        if c in breed_cols:\n            table[c] = table[c].str.lower()\n\n# Call the function\nlowercase(image_clean)\n\n# Confirm\nimage_clean.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Code 2:","metadata":{}},{"cell_type":"code","source":"# Round decimal numbers\nfor c in image_clean.columns:\n    if c[-4:] == \"conf\":\n        image_clean[c] = image_clean[c].round(3)\n\n# Confirm\nimage_clean.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Clean 7(add_clean)\nDefine: \n- Replace invalid rating_denominator with 10\n\nCode:","metadata":{"execution":{"iopub.status.busy":"2022-10-15T10:31:15.940203Z","iopub.execute_input":"2022-10-15T10:31:15.940719Z","iopub.status.idle":"2022-10-15T10:31:15.948196Z","shell.execute_reply.started":"2022-10-15T10:31:15.940680Z","shell.execute_reply":"2022-10-15T10:31:15.946674Z"}}},{"cell_type":"code","source":"# Create a mask for`rating_denominator` value other than 10.\nmask = tweets_clean['rating_denominator'] != 10\n\n# Then assign the value of 10 to those wrong entries.\ntweets_clean.loc[mask, 'rating_denominator'] = 10\n\n# Confirm\ntweets_clean.query('rating_denominator != 10')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Clean 8 (tweets_clean) \nDefine: \n- Replace non-name values (e.g. None, very) to Nan \n\nCode:","metadata":{}},{"cell_type":"code","source":"# Convert invalid names to NaN: np.nan()\nnon_name = ['None', 'very', 'incredibly', 'his', 'just', 'getting', 'mad', 'this', 'unacceptable', 'all', \n            'old', 'by', 'life', 'light', 'space', 'a']\n        \n\nfor n in tweets_clean['name']:\n    if n in non_name:\n        n = None\n\ntweets_clean[tweets_clean['name']=='None']","metadata":{"execution":{"iopub.status.busy":"2022-10-15T11:41:12.518277Z","iopub.execute_input":"2022-10-15T11:41:12.518713Z","iopub.status.idle":"2022-10-15T11:41:12.536466Z","shell.execute_reply.started":"2022-10-15T11:41:12.518673Z","shell.execute_reply":"2022-10-15T11:41:12.535174Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [tweet_id, in_reply_to_status_id, in_reply_to_user_id, timestamp, source, text, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp, expanded_urls, rating_numerator, rating_denominator, name, doggo, floofer, pupper, puppo]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>in_reply_to_status_id</th>\n      <th>in_reply_to_user_id</th>\n      <th>timestamp</th>\n      <th>source</th>\n      <th>text</th>\n      <th>retweeted_status_id</th>\n      <th>retweeted_status_user_id</th>\n      <th>retweeted_status_timestamp</th>\n      <th>expanded_urls</th>\n      <th>rating_numerator</th>\n      <th>rating_denominator</th>\n      <th>name</th>\n      <th>doggo</th>\n      <th>floofer</th>\n      <th>pupper</th>\n      <th>puppo</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}